# =============================================================================
# ADPA Production Environment Configuration Template
# =============================================================================
# Copy this file to .env and configure your preferred AI providers
# Multiple providers can be configured for automatic fallback support

# =============================================================================
# PRIMARY AI PROVIDER CONFIGURATION
# =============================================================================
# Set your primary provider (recommended: google-ai for free tier, azure-openai-entra for enterprise)
PRIMARY_AI_PROVIDER=google-ai

# =============================================================================
# GOOGLE AI STUDIO CONFIGURATION (Recommended - Free Tier)
# =============================================================================
# Get your API key from: https://makersuite.google.com/app/apikey
# Features: 1M-2M token context, generous free tier, fast response
GOOGLE_AI_API_KEY=your-google-ai-api-key-here
GOOGLE_AI_MODEL=gemini-1.5-flash
GOOGLE_AI_ENABLED=true

# =============================================================================
# GITHUB AI CONFIGURATION (Free for GitHub Users)
# =============================================================================
# Get your token from: https://github.com/settings/tokens
# Features: Free for GitHub users, GPT-4o-mini access
GITHUB_TOKEN=your-github-token-here
GITHUB_ENDPOINT=https://models.github.ai/inference/
GITHUB_AI_MODEL=gpt-4o-mini
GITHUB_AI_ENABLED=true

# =============================================================================
# AZURE OPENAI CONFIGURATION (Enterprise)
# =============================================================================
# Option 1: Entra ID Authentication (Recommended for Enterprise)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_CLIENT_ID=your-client-id
AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_SECRET=your-client-secret
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview
USE_ENTRA_ID=true
AZURE_OPENAI_ENTRA_ENABLED=true

# Option 2: API Key Authentication (Alternative)
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_KEY_ENABLED=true

# =============================================================================
# OLLAMA LOCAL AI CONFIGURATION (Privacy-Focused)
# =============================================================================
# For offline/local processing - requires Ollama installation
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.1
OLLAMA_ENABLED=false

# =============================================================================
# FALLBACK AND RELIABILITY CONFIGURATION
# =============================================================================
# Enable automatic provider fallback when primary provider fails
ENABLE_PROVIDER_FALLBACK=true

# Provider priority order (comma-separated, highest priority first)
PROVIDER_FALLBACK_ORDER=google-ai,github-ai,azure-openai-entra,azure-openai-key,ollama

# Health check intervals (in milliseconds)
PROVIDER_HEALTH_CHECK_INTERVAL=300000  # 5 minutes
PROVIDER_HEALTH_CHECK_TIMEOUT=10000    # 10 seconds

# Circuit breaker configuration
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIME=60000    # 1 minute
CIRCUIT_BREAKER_HALF_OPEN_MAX_CALLS=3

# Retry configuration
MAX_RETRIES=3
RETRY_BASE_DELAY=1000                  # 1 second
RETRY_MAX_DELAY=30000                  # 30 seconds
RETRY_BACKOFF_MULTIPLIER=2

# =============================================================================
# PERFORMANCE OPTIMIZATION
# =============================================================================
# AI request timeout (in milliseconds)
AI_TIMEOUT=60000                       # 60 seconds

# Enable request caching to improve performance
ENABLE_REQUEST_CACHING=true
CACHE_TTL=3600000                      # 1 hour

# Enable metrics collection for performance monitoring
ENABLE_METRICS=true
METRICS_COLLECTION_INTERVAL=60000      # 1 minute

# Token usage monitoring
ENABLE_TOKEN_MONITORING=true
DAILY_TOKEN_LIMIT_WARNING_THRESHOLD=0.8  # Warn at 80% of daily limit

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
OUTPUT_DIR=./generated-documents
PREFERRED_FORMAT=markdown
SHOW_METRICS=true
EXPERIMENTAL_FEATURES=true

# =============================================================================
# INTEGRATION CONFIGURATION
# =============================================================================
# Version Control Integration
DOCS_VCS_ENABLED=true
DOCS_VCS_AUTO_COMMIT=true
DOCS_VCS_BRANCH=main

# Confluence Integration
CONFLUENCE_BASE_URL=https://your-domain.atlassian.net
CONFLUENCE_EMAIL=your-email@domain.com
CONFLUENCE_SPACE_KEY=YOUR_SPACE
CONFLUENCE_ENABLED=false

# SharePoint Integration
SHAREPOINT_TENANT_ID=your-tenant-id
SHAREPOINT_CLIENT_ID=your-client-id
SHAREPOINT_SITE_URL=https://your-domain.sharepoint.com/sites/your-site
SHAREPOINT_ENABLED=false

# =============================================================================
# LOGGING AND DEBUGGING
# =============================================================================
LOG_LEVEL=info                         # debug, info, warn, error
ENABLE_DEBUG_LOGGING=false
LOG_AI_REQUESTS=false                  # Set to true for debugging (may log sensitive data)
LOG_PERFORMANCE_METRICS=true