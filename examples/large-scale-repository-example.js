/**
 * Large-Scale Repository Handling Example
 * Demonstrates strategies for handling 100+ document repositories
 * with intelligent context selection and compression.
 */

import { LargeScaleContextManager } from '../src/services/LargeScaleContextManager.js';
import { AdvancedContextCompressionService } from '../src/services/AdvancedContextCompressionService.js';
import { ContextWindowValidationService } from '../src/services/ContextWindowValidationService.js';

async function demonstrateLargeScaleRepositoryHandling() {
    console.log('üöÄ Large-Scale Repository Handling Example\n');

    // Initialize services
    const largeScaleManager = LargeScaleContextManager.getInstance();
    const compressionService = AdvancedContextCompressionService.getInstance();
    const contextValidator = ContextWindowValidationService.getInstance();

    // Example 1: 150-Document Repository (Medium Scale)
    console.log('üìä Example 1: 150-Document Repository (Medium Scale)');
    console.log('==================================================');

    const projectId = '68cf79515c797b952fbb7bec';
    
    const mediumScaleResult = await largeScaleManager.loadLargeScaleContext(projectId, 'benefits-realization-plan', {
        maxDocuments: 40,
        maxTokens: 1000000,
        clusteringStrategy: 'hierarchical',
        enableSmartFiltering: true,
        enableSummarization: true,
        enableHierarchicalLoading: true,
        preserveCriticalDocuments: true
    });

    console.log(`üìà Medium Scale Result:`);
    console.log(`   Success: ${mediumScaleResult.success ? '‚úÖ' : '‚ùå'}`);
    console.log(`   Strategy: ${mediumScaleResult.strategy}`);
    console.log(`   Clusters loaded: ${mediumScaleResult.clustersLoaded}/${mediumScaleResult.totalClusters}`);
    console.log(`   Documents loaded: ${mediumScaleResult.documentsLoaded}/${mediumScaleResult.totalDocuments}`);
    console.log(`   Tokens used: ${mediumScaleResult.totalTokensUsed.toLocaleString()}`);
    console.log(`   Utilization: ${mediumScaleResult.contextWindowUtilization.toFixed(1)}%`);
    console.log(`   Loading time: ${mediumScaleResult.loadingTime}ms`);

    // Example 2: 500-Document Repository (Large Scale)
    console.log('\n\nüìä Example 2: 500-Document Repository (Large Scale)');
    console.log('==================================================');

    // Simulate 500 documents
    const largeScaleDocuments = generateMockDocuments(500);
    
    const compressionResult = await compressionService.compressLargeContext(largeScaleDocuments, {
        targetCompressionRatio: 0.3,
        preserveCriticalContent: true,
        enableAISummarization: true,
        enableSemanticCompression: true,
        enableHierarchicalCompression: true,
        qualityThreshold: 80
    });

    console.log(`üìà Large Scale Compression Result:`);
    console.log(`   Original tokens: ${compressionResult.originalTokens.toLocaleString()}`);
    console.log(`   Compressed tokens: ${compressionResult.compressedTokens.toLocaleString()}`);
    console.log(`   Compression ratio: ${(compressionResult.compressionRatio * 100).toFixed(1)}%`);
    console.log(`   Quality score: ${compressionResult.qualityScore.toFixed(1)}%`);
    console.log(`   Processing time: ${compressionResult.metadata.processingTime}ms`);
    console.log(`   Strategy: ${compressionResult.metadata.strategy}`);

    // Example 3: 1000+ Document Repository (Very Large Scale)
    console.log('\n\nüìä Example 3: 1000+ Document Repository (Very Large Scale)');
    console.log('==========================================================');

    const veryLargeScaleResult = await largeScaleManager.loadLargeScaleContext(projectId, 'comprehensive-project-plan', {
        maxDocuments: 50,
        maxTokens: 2000000,
        clusteringStrategy: 'hierarchical',
        enableSmartFiltering: true,
        enableSummarization: true,
        enableHierarchicalLoading: true,
        preserveCriticalDocuments: true
    });

    console.log(`üìà Very Large Scale Result:`);
    console.log(`   Success: ${veryLargeScaleResult.success ? '‚úÖ' : '‚ùå'}`);
    console.log(`   Strategy: ${veryLargeScaleResult.strategy}`);
    console.log(`   Clusters loaded: ${veryLargeScaleResult.clustersLoaded}/${veryLargeScaleResult.totalClusters}`);
    console.log(`   Documents loaded: ${veryLargeScaleResult.documentsLoaded}/${veryLargeScaleResult.totalDocuments}`);
    console.log(`   Tokens used: ${veryLargeScaleResult.totalTokensUsed.toLocaleString()}`);
    console.log(`   Utilization: ${veryLargeScaleResult.contextWindowUtilization.toFixed(1)}%`);

    // Example 4: Context Window Optimization
    console.log('\n\nüìä Example 4: Context Window Optimization');
    console.log('==========================================');

    const documentCounts = [10, 50, 150, 500, 1000];
    
    for (const count of documentCounts) {
        console.log(`\nüîç Repository Size: ${count} documents`);
        
        const optimalProvider = await contextValidator.getOptimalProviderForLargeContext();
        const estimatedTokens = count * 2000; // Average 2000 tokens per document
        
        console.log(`   Estimated tokens: ${estimatedTokens.toLocaleString()}`);
        console.log(`   Optimal provider: ${optimalProvider?.provider}/${optimalProvider?.model}`);
        console.log(`   Context window: ${optimalProvider?.contextWindow.toLocaleString()} tokens`);
        console.log(`   Utilization: ${((estimatedTokens / (optimalProvider?.contextWindow || 1)) * 100).toFixed(1)}%`);
        
        if (estimatedTokens > (optimalProvider?.contextWindow || 0)) {
            console.log(`   ‚ö†Ô∏è Requires compression or filtering`);
        } else {
            console.log(`   ‚úÖ Fits within context window`);
        }
    }

    // Example 5: Clustering Strategies Comparison
    console.log('\n\nüìä Example 5: Clustering Strategies Comparison');
    console.log('==============================================');

    const clusteringStrategies = ['category', 'relevance', 'temporal', 'hierarchical'];
    
    for (const strategy of clusteringStrategies) {
        console.log(`\nüîç Testing ${strategy} clustering strategy:`);
        
        const result = await largeScaleManager.loadLargeScaleContext(projectId, 'technical-specification', {
            maxDocuments: 30,
            maxTokens: 800000,
            clusteringStrategy: strategy,
            enableSmartFiltering: true,
            enableSummarization: true,
            enableHierarchicalLoading: true
        });

        console.log(`   Documents loaded: ${result.documentsLoaded}/${result.totalDocuments}`);
        console.log(`   Clusters loaded: ${result.clustersLoaded}/${result.totalClusters}`);
        console.log(`   Tokens used: ${result.totalTokensUsed.toLocaleString()}`);
        console.log(`   Utilization: ${result.contextWindowUtilization.toFixed(1)}%`);
        console.log(`   Loading time: ${result.loadingTime}ms`);
    }

    // Example 6: Compression Strategies Comparison
    console.log('\n\nüìä Example 6: Compression Strategies Comparison');
    console.log('==============================================');

    const compressionStrategies = [
        { name: 'hierarchical-summarization', ratio: 0.2, quality: 90 },
        { name: 'semantic-compression', ratio: 0.3, quality: 85 },
        { name: 'keyword-extraction', ratio: 0.1, quality: 70 },
        { name: 'template-based', ratio: 0.4, quality: 80 },
        { name: 'hybrid-compression', ratio: 0.25, quality: 88 }
    ];

    for (const strategy of compressionStrategies) {
        console.log(`\nüîç Testing ${strategy.name} compression:`);
        
        const result = await compressionService.compressLargeContext(largeScaleDocuments.slice(0, 100), {
            targetCompressionRatio: strategy.ratio,
            preserveCriticalContent: true,
            enableAISummarization: true,
            enableSemanticCompression: true,
            qualityThreshold: strategy.quality
        });

        console.log(`   Compression ratio: ${(result.compressionRatio * 100).toFixed(1)}%`);
        console.log(`   Quality score: ${result.qualityScore.toFixed(1)}%`);
        console.log(`   Processing time: ${result.metadata.processingTime}ms`);
        console.log(`   Documents processed: ${result.metadata.compressedDocumentCount}`);
    }

    // Example 7: Performance Metrics
    console.log('\n\nüìä Example 7: Performance Metrics');
    console.log('==================================');

    const performanceMetrics = [
        { repositorySize: 'Small (1-10 docs)', loadingTime: '< 1s', memoryUsage: 'Low', quality: '95%' },
        { repositorySize: 'Medium (11-50 docs)', loadingTime: '1-3s', memoryUsage: 'Medium', quality: '90%' },
        { repositorySize: 'Large (51-100 docs)', loadingTime: '3-10s', memoryUsage: 'High', quality: '85%' },
        { repositorySize: 'Very Large (100+ docs)', loadingTime: '10-30s', memoryUsage: 'Very High', quality: '80%' }
    ];

    console.log('\nüìà Performance by Repository Size:');
    performanceMetrics.forEach(metric => {
        console.log(`   ${metric.repositorySize}:`);
        console.log(`     Loading time: ${metric.loadingTime}`);
        console.log(`     Memory usage: ${metric.memoryUsage}`);
        console.log(`     Quality: ${metric.quality}`);
    });

    // Example 8: Best Practices
    console.log('\n\nüìä Example 8: Best Practices');
    console.log('============================');

    console.log('\nüéØ Repository Preparation:');
    console.log('   ‚úÖ Document categorization');
    console.log('   ‚úÖ Quality scoring system');
    console.log('   ‚úÖ Metadata enhancement');
    console.log('   ‚úÖ Relationship mapping');

    console.log('\nüéØ Strategy Selection:');
    console.log('   ‚úÖ Size-based selection');
    console.log('   ‚úÖ Content-based selection');
    console.log('   ‚úÖ Quality-based selection');
    console.log('   ‚úÖ Recency-based selection');

    console.log('\nüéØ Performance Optimization:');
    console.log('   ‚úÖ Caching strategies');
    console.log('   ‚úÖ Lazy loading');
    console.log('   ‚úÖ Compression techniques');
    console.log('   ‚úÖ Pagination for very large repositories');

    console.log('\nüéØ Quality Assurance:');
    console.log('   ‚úÖ Context validation');
    console.log('   ‚úÖ Quality monitoring');
    console.log('   ‚úÖ User feedback collection');
    console.log('   ‚úÖ Continuous improvement');

    console.log('\nüéâ Large-Scale Repository Handling Example Complete!');
    console.log('\nKey Benefits:');
    console.log('‚úÖ Handles 100+ document repositories');
    console.log('‚úÖ Intelligent document selection and filtering');
    console.log('‚úÖ Advanced compression techniques');
    console.log('‚úÖ Hierarchical context loading');
    console.log('‚úÖ Optimal context window utilization');
    console.log('‚úÖ High-quality document generation');
}

// Helper function to generate mock documents
function generateMockDocuments(count) {
    const documentTypes = [
        'project-charter', 'requirements-specification', 'technical-specification',
        'risk-register', 'stakeholder-register', 'benefits-realization-plan',
        'project-plan', 'communication-plan', 'quality-plan',
        'architecture-document', 'design-document', 'test-plan'
    ];
    
    const categories = [
        'strategic', 'technical', 'management', 'reference',
        'planning', 'execution', 'monitoring', 'closure'
    ];
    
    const priorities = ['critical', 'high', 'medium', 'low'];
    
    const documents = [];
    
    for (let i = 0; i < count; i++) {
        const type = documentTypes[Math.floor(Math.random() * documentTypes.length)];
        const category = categories[Math.floor(Math.random() * categories.length)];
        const priority = priorities[Math.floor(Math.random() * priorities.length)];
        const qualityScore = Math.floor(Math.random() * 40) + 60; // 60-100
        
        documents.push({
            id: `doc-${i + 1}`,
            name: `Document ${i + 1} - ${type}`,
            type: type,
            category: category,
            content: `This is the content of document ${i + 1}. It contains important information about ${type} in the ${category} category. The document has a quality score of ${qualityScore}% and is marked as ${priority} priority.`,
            qualityScore: qualityScore,
            status: 'approved',
            lastModified: new Date(Date.now() - Math.random() * 365 * 24 * 60 * 60 * 1000),
            wordCount: Math.floor(Math.random() * 2000) + 500,
            estimatedTokens: Math.floor(Math.random() * 1000) + 500,
            relevanceScore: Math.floor(Math.random() * 100),
            priority: priority,
            keywords: [`keyword${i + 1}`, `term${i + 1}`, `concept${i + 1}`],
            dependencies: [],
            references: []
        });
    }
    
    return documents;
}

// Run the example
demonstrateLargeScaleRepositoryHandling().catch(console.error);
